{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.spatial import distance_matrix\n",
    "import networkx as nx\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Utils for vector field processing\n",
    "def generate_vector_field_map(node_coords, height, width):\n",
    "    # A function that generates the vector field based on node coordinates\n",
    "    vector_field = np.zeros((height, width, 2))  \n",
    "    for i in range(len(node_coords) - 1):\n",
    "        start = node_coords[i]\n",
    "        end = node_coords[i + 1]\n",
    "        cv2.line(vector_field, tuple(start), tuple(end), (1, 1), 2)  # simplified example\n",
    "    return vector_field\n",
    "\n",
    "def compute_resistivity(node_a, node_b, vector_field):\n",
    "    vector = node_b - node_a\n",
    "    alignment = np.dot(vector, vector_field[node_a[1], node_a[0]]) / np.linalg.norm(vector)\n",
    "    distance = np.linalg.norm(vector)\n",
    "    return (1 - alignment) * distance\n",
    "\n",
    "# Utils for data processing\n",
    "def load_annotation(json_file):\n",
    "    \"\"\"Load JSON annotation for a vine image.\"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        annotation = json.load(f)\n",
    "    return annotation\n",
    "\n",
    "def parse_features(annotation):\n",
    "    \"\"\"Extract vine features (nodes and branch labels) from the annotation JSON.\"\"\"\n",
    "    # Access the 'VineImage' list, and then the 'VineFeature' inside it\n",
    "    vine_images = annotation.get('VineImage', None)\n",
    "    \n",
    "    if vine_images is None or len(vine_images) == 0:\n",
    "        raise KeyError(\"'VineImage' key not found or empty in the JSON file. Check the JSON structure.\")\n",
    "    \n",
    "    # Assuming we are dealing with the first image in the list\n",
    "    features = vine_images[0].get('VineFeature', None)\n",
    "    \n",
    "    if features is None:\n",
    "        raise KeyError(\"'VineFeature' key not found in the JSON file under 'VineImage'. Check the JSON structure.\")\n",
    "    \n",
    "    nodes = []\n",
    "    branches = []\n",
    "    \n",
    "    # The `VineFeature` is a list of lists, so we need to iterate over each inner list\n",
    "    for feature_list in features:\n",
    "        for feature in feature_list:\n",
    "            # Check for 'FeatureType' and other keys\n",
    "            if 'FeatureType' in feature:\n",
    "                if feature['FeatureType'] in ['rootCrown', 'branchNode', 'growingTip', 'pruningCut']:\n",
    "                    nodes.append({\n",
    "                        'id': feature['FeatureID'],\n",
    "                        'coordinates': feature['FeatureCoordinates'],\n",
    "                        'type': feature['FeatureType']\n",
    "                    })\n",
    "            if 'ParentID' in feature:\n",
    "                branches.append({\n",
    "                    'parent_id': feature['ParentID'],\n",
    "                    'child_id': feature['FeatureID'],\n",
    "                    'branch_label': feature.get('BranchLabel', 'unknown')  # Use default if BranchLabel is missing\n",
    "                })\n",
    "    \n",
    "    return nodes, branches\n",
    "\n",
    "\n",
    "def generate_heatmaps(nodes, image_width, image_height):\n",
    "    \"\"\"Generate Gaussian heatmaps for node positions.\"\"\"\n",
    "    heatmaps = np.zeros((len(nodes), image_height, image_width), dtype=np.float32)\n",
    "    for i, node in enumerate(nodes):\n",
    "        coord = node['coordinates']\n",
    "        x, y = coord\n",
    "        heatmap = np.zeros((image_height, image_width))\n",
    "        heatmap[x, y] = 1\n",
    "        heatmap = gaussian_filter(heatmap, sigma=2)\n",
    "        heatmaps[i] = heatmap\n",
    "    return heatmaps\n",
    "\n",
    "\n",
    "class VineDataset(Dataset):\n",
    "    \"\"\"Custom dataset for vine images and annotations stored in the same folder.\"\"\"\n",
    "    def __init__(self, data_dir, height=256, width=256):\n",
    "        self.data_dir = data_dir\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.image_files = [f for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_file = self.image_files[idx]\n",
    "        img_path = os.path.join(self.data_dir, img_file)\n",
    "        annotation_path = os.path.join(self.data_dir, img_file.replace('.jpg', '_annotation.json'))\n",
    "\n",
    "        # Load and resize image\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.resize(image, (self.width, self.height))\n",
    "\n",
    "        # Load and parse annotation\n",
    "        annotation = load_annotation(annotation_path)\n",
    "        nodes, branches = parse_features(annotation)\n",
    "\n",
    "        # Generate heatmaps for nodes\n",
    "        heatmaps = generate_heatmaps(nodes, self.height, self.width)\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "        heatmaps = torch.from_numpy(heatmaps).float()\n",
    "\n",
    "        return image, heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Hourglass Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class HourglassBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(HourglassBlock, self).__init__()\n",
    "        self.downsample = nn.MaxPool2d(2, stride=2)\n",
    "        self.residual = ResidualBlock(in_channels, out_channels)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, x):\n",
    "        down = self.downsample(x)\n",
    "        down = self.residual(down)\n",
    "        up = self.upsample(down)\n",
    "        return up + x\n",
    "\n",
    "class StackedHourglassNetwork(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(StackedHourglassNetwork, self).__init__()\n",
    "        self.hg1 = HourglassBlock(in_channels, out_channels)\n",
    "        self.hg2 = HourglassBlock(out_channels, out_channels)\n",
    "        self.final_layer = nn.Conv2d(out_channels, 1, kernel_size=1)  # output heatmap\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hg1(x)\n",
    "        x = self.hg2(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Instantiate the model\n",
    "model = StackedHourglassNetwork(3, 256).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Reconstruction with Graph Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_resistivity_graph(node_coords, vector_field):\n",
    "    G = nx.Graph()\n",
    "    for i, node_a in enumerate(node_coords):\n",
    "        for j, node_b in enumerate(node_coords):\n",
    "            if i != j:\n",
    "                resistivity = compute_resistivity(node_a, node_b, vector_field)\n",
    "                G.add_edge(i, j, weight=resistivity)\n",
    "    return G\n",
    "\n",
    "def reconstruct_tree(node_coords, vector_field):\n",
    "    G = build_resistivity_graph(node_coords, vector_field)\n",
    "    # Use shortest path to reconstruct tree structure\n",
    "    mst = nx.minimum_spanning_tree(G)\n",
    "    return mst\n",
    "\n",
    "# Example usage\n",
    "node_coords = np.array([[100, 200], [150, 220], [200, 300]])  # dummy node coordinates\n",
    "vector_field = generate_vector_field_map(node_coords, 512,512)\n",
    "tree_structure = reconstruct_tree(node_coords, vector_field)\n",
    "\n",
    "# Visualize the tree structure\n",
    "import matplotlib.pyplot as plt\n",
    "nx.draw(tree_structure, with_labels=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.09 GiB for an array with shape (112, 4032, 3024) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheatmaps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheatmaps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheatmaps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Università\\Alta Scuola Politecnica\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Università\\Alta Scuola Politecnica\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Università\\Alta Scuola Politecnica\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[1], line 112\u001b[0m, in \u001b[0;36mVineDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    109\u001b[0m nodes, branches \u001b[38;5;241m=\u001b[39m parse_features(annotation)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Generate heatmaps for nodes\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m heatmaps \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_heatmaps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Convert to PyTorch tensors\u001b[39;00m\n\u001b[0;32m    115\u001b[0m image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(image)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "Cell \u001b[1;32mIn[1], line 76\u001b[0m, in \u001b[0;36mgenerate_heatmaps\u001b[1;34m(nodes, image_width, image_height)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_heatmaps\u001b[39m(nodes, image_width, image_height):\n\u001b[0;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate Gaussian heatmaps for node positions.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     heatmaps \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_width\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nodes):\n\u001b[0;32m     78\u001b[0m         coord \u001b[38;5;241m=\u001b[39m node[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.09 GiB for an array with shape (112, 4032, 3024) and data type float32"
     ]
    }
   ],
   "source": [
    "# Define dataset and dataloader\n",
    "train_dataset = VineDataset(data_dir='./3D2cut_Single_Guyot/01-TrainAndValidationSet', height=3024, width=4032) # TODO: split into train and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Loss for heatmap predictions\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    for images, heatmaps in train_loader:\n",
    "        images, heatmaps = images.to(device), heatmaps.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, heatmaps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
